{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../datasets/local/vis_papers/raw/IEEE VIS papers 1990-2022 - Main dataset.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conference</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Link</th>\n",
       "      <th>FirstPage</th>\n",
       "      <th>LastPage</th>\n",
       "      <th>PaperType</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>AuthorNames-Deduped</th>\n",
       "      <th>AuthorNames</th>\n",
       "      <th>AuthorAffiliation</th>\n",
       "      <th>InternalReferences</th>\n",
       "      <th>AuthorKeywords</th>\n",
       "      <th>AminerCitationCount</th>\n",
       "      <th>CitationCount_CrossRef</th>\n",
       "      <th>PubsCited_CrossRef</th>\n",
       "      <th>Award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vis</td>\n",
       "      <td>2022</td>\n",
       "      <td>Photosensitive Accessibility for Interactive D...</td>\n",
       "      <td>10.1109/TVCG.2022.3209359</td>\n",
       "      <td>http://dx.doi.org/10.1109/TVCG.2022.3209359</td>\n",
       "      <td>374</td>\n",
       "      <td>384</td>\n",
       "      <td>J</td>\n",
       "      <td>Accessibility guidelines place restrictions on...</td>\n",
       "      <td>Laura South;Michelle Borkin</td>\n",
       "      <td>Laura South;Michelle A. Borkin</td>\n",
       "      <td>Northeastern University, USA;Northeastern Univ...</td>\n",
       "      <td>10.1109/TVCG.2011.185;10.1109/TVCG.2021.311482...</td>\n",
       "      <td>accessibility,photosensitive epilepsy,photosen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vis</td>\n",
       "      <td>2022</td>\n",
       "      <td>HetVis: A Visual Analysis Approach for Identif...</td>\n",
       "      <td>10.1109/TVCG.2022.3209347</td>\n",
       "      <td>http://dx.doi.org/10.1109/TVCG.2022.3209347</td>\n",
       "      <td>310</td>\n",
       "      <td>319</td>\n",
       "      <td>J</td>\n",
       "      <td>Horizontal federated learning (HFL) enables di...</td>\n",
       "      <td>Xumeng Wang;Wei Chen 0001;Jiazhi Xia;Zhen Wen;...</td>\n",
       "      <td>Xumeng Wang;Wei Chen;Jiazhi Xia;Zhen Wen;Rongc...</td>\n",
       "      <td>TMCC, CS, Nankai University, China;State Key L...</td>\n",
       "      <td>10.1109/TVCG.2015.2467618;10.1109/TVCG.2019.29...</td>\n",
       "      <td>Federated learning,data heterogeneity,cluster ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vis</td>\n",
       "      <td>2022</td>\n",
       "      <td>Rigel: Transforming Tabular Data by Declarativ...</td>\n",
       "      <td>10.1109/TVCG.2022.3209385</td>\n",
       "      <td>http://dx.doi.org/10.1109/TVCG.2022.3209385</td>\n",
       "      <td>128</td>\n",
       "      <td>138</td>\n",
       "      <td>J</td>\n",
       "      <td>We present Rigel, an interactive system for ra...</td>\n",
       "      <td>Ran Chen;Di Weng;Yanwei Huang;Xinhuan Shu;Jiay...</td>\n",
       "      <td>Ran Chen;Di Weng;Yanwei Huang;Xinhuan Shu;Jiay...</td>\n",
       "      <td>State Key Lab of CAD&amp;CG, Zhejiang University, ...</td>\n",
       "      <td>10.1109/TVCG.2021.3114830;10.1109/VAST47406.20...</td>\n",
       "      <td>Data transformation,self-service data transfor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vis</td>\n",
       "      <td>2022</td>\n",
       "      <td>BeauVis: A Validated Scale for Measuring the A...</td>\n",
       "      <td>10.1109/TVCG.2022.3209390</td>\n",
       "      <td>http://dx.doi.org/10.1109/TVCG.2022.3209390</td>\n",
       "      <td>363</td>\n",
       "      <td>373</td>\n",
       "      <td>J</td>\n",
       "      <td>We developed and validated a rating scale to a...</td>\n",
       "      <td>Tingying He;Petra Isenberg;Raimund Dachselt;To...</td>\n",
       "      <td>Tingying He;Petra Isenberg;Raimund Dachselt;To...</td>\n",
       "      <td>Universit√© Paris-Saclay, CNRS, Inria, LISN, Fr...</td>\n",
       "      <td>10.1109/INFVIS.2005.1532128;10.1109/TVCG.2006....</td>\n",
       "      <td>Aesthetics,aesthetic pleasure,validated scale,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vis</td>\n",
       "      <td>2022</td>\n",
       "      <td>NAS-Navigator: Visual Steering for Explainable...</td>\n",
       "      <td>10.1109/TVCG.2022.3209361</td>\n",
       "      <td>http://dx.doi.org/10.1109/TVCG.2022.3209361</td>\n",
       "      <td>299</td>\n",
       "      <td>309</td>\n",
       "      <td>J</td>\n",
       "      <td>The success of DL can be attributed to hours o...</td>\n",
       "      <td>Anjul Tyagi;Cong Xie;Klaus Mueller 0001</td>\n",
       "      <td>Anjul Tyagi;Cong Xie;Klaus Mueller</td>\n",
       "      <td>Computer Science Department, Visual Analytics ...</td>\n",
       "      <td>10.1109/VAST.2012.6400490;10.1109/TVCG.2019.29...</td>\n",
       "      <td>Deep Learning,Neural Network Architecture Sear...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1990</td>\n",
       "      <td>Visualization and three-dimensional image proc...</td>\n",
       "      <td>10.1109/VISUAL.1990.146376</td>\n",
       "      <td>http://dx.doi.org/10.1109/VISUAL.1990.146376</td>\n",
       "      <td>144</td>\n",
       "      <td>149, 469</td>\n",
       "      <td>C</td>\n",
       "      <td>The author applied image processing and volume...</td>\n",
       "      <td>Nahum D. Gershon</td>\n",
       "      <td>N.D. Gershon</td>\n",
       "      <td>MITRE Corporation, Mclean, VA, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1990</td>\n",
       "      <td>Case study in scientific visualization: factor...</td>\n",
       "      <td>10.1109/VISUAL.1990.146415</td>\n",
       "      <td>http://dx.doi.org/10.1109/VISUAL.1990.146415</td>\n",
       "      <td>430</td>\n",
       "      <td>434</td>\n",
       "      <td>C</td>\n",
       "      <td>The problem of presenting and gaining deeper u...</td>\n",
       "      <td>Wayne E. Fordyce;Jeffrey Ventrella</td>\n",
       "      <td>W.E. Fordyce;J.J. Ventrella</td>\n",
       "      <td>Research Computing Services, Syracuse Universi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1990</td>\n",
       "      <td>Hierarchical triangulation using terrain features</td>\n",
       "      <td>10.1109/VISUAL.1990.146379</td>\n",
       "      <td>http://dx.doi.org/10.1109/VISUAL.1990.146379</td>\n",
       "      <td>168</td>\n",
       "      <td>175</td>\n",
       "      <td>C</td>\n",
       "      <td>A hierarchical triangulation built from a digi...</td>\n",
       "      <td>Lori L. Scarlatos;Theodosios Pavlidis</td>\n",
       "      <td>L. Scarlatos;T. Pavlidis</td>\n",
       "      <td>Grumman Data Systems, Woodbury, NY, USA;Depart...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1990</td>\n",
       "      <td>A methodology for scientific data visualisatio...</td>\n",
       "      <td>10.1109/VISUAL.1990.146372</td>\n",
       "      <td>http://dx.doi.org/10.1109/VISUAL.1990.146372</td>\n",
       "      <td>114</td>\n",
       "      <td>123</td>\n",
       "      <td>C</td>\n",
       "      <td>A methodology for guiding the choice of visual...</td>\n",
       "      <td>Philip K. Robertson</td>\n",
       "      <td>P.K. Robertson</td>\n",
       "      <td>Centre for Spatial Information Systems, Divisi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>Vis</td>\n",
       "      <td>1990</td>\n",
       "      <td>The application of transport theory to visuali...</td>\n",
       "      <td>10.1109/VISUAL.1990.146391</td>\n",
       "      <td>http://dx.doi.org/10.1109/VISUAL.1990.146391</td>\n",
       "      <td>273</td>\n",
       "      <td>280, 481-2</td>\n",
       "      <td>C</td>\n",
       "      <td>The author describes a visualization model for...</td>\n",
       "      <td>Wolfgang Kr√ºger</td>\n",
       "      <td>W. Krueger</td>\n",
       "      <td>ART COM e.V., Berlin, Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3620 rows √ó 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Conference  Year                                              Title  \\\n",
       "0           Vis  2022  Photosensitive Accessibility for Interactive D...   \n",
       "1           Vis  2022  HetVis: A Visual Analysis Approach for Identif...   \n",
       "2           Vis  2022  Rigel: Transforming Tabular Data by Declarativ...   \n",
       "3           Vis  2022  BeauVis: A Validated Scale for Measuring the A...   \n",
       "4           Vis  2022  NAS-Navigator: Visual Steering for Explainable...   \n",
       "...         ...   ...                                                ...   \n",
       "3615        Vis  1990  Visualization and three-dimensional image proc...   \n",
       "3616        Vis  1990  Case study in scientific visualization: factor...   \n",
       "3617        Vis  1990  Hierarchical triangulation using terrain features   \n",
       "3618        Vis  1990  A methodology for scientific data visualisatio...   \n",
       "3619        Vis  1990  The application of transport theory to visuali...   \n",
       "\n",
       "                             DOI  \\\n",
       "0      10.1109/TVCG.2022.3209359   \n",
       "1      10.1109/TVCG.2022.3209347   \n",
       "2      10.1109/TVCG.2022.3209385   \n",
       "3      10.1109/TVCG.2022.3209390   \n",
       "4      10.1109/TVCG.2022.3209361   \n",
       "...                          ...   \n",
       "3615  10.1109/VISUAL.1990.146376   \n",
       "3616  10.1109/VISUAL.1990.146415   \n",
       "3617  10.1109/VISUAL.1990.146379   \n",
       "3618  10.1109/VISUAL.1990.146372   \n",
       "3619  10.1109/VISUAL.1990.146391   \n",
       "\n",
       "                                              Link FirstPage    LastPage  \\\n",
       "0      http://dx.doi.org/10.1109/TVCG.2022.3209359       374         384   \n",
       "1      http://dx.doi.org/10.1109/TVCG.2022.3209347       310         319   \n",
       "2      http://dx.doi.org/10.1109/TVCG.2022.3209385       128         138   \n",
       "3      http://dx.doi.org/10.1109/TVCG.2022.3209390       363         373   \n",
       "4      http://dx.doi.org/10.1109/TVCG.2022.3209361       299         309   \n",
       "...                                            ...       ...         ...   \n",
       "3615  http://dx.doi.org/10.1109/VISUAL.1990.146376       144    149, 469   \n",
       "3616  http://dx.doi.org/10.1109/VISUAL.1990.146415       430         434   \n",
       "3617  http://dx.doi.org/10.1109/VISUAL.1990.146379       168         175   \n",
       "3618  http://dx.doi.org/10.1109/VISUAL.1990.146372       114         123   \n",
       "3619  http://dx.doi.org/10.1109/VISUAL.1990.146391       273  280, 481-2   \n",
       "\n",
       "     PaperType                                           Abstract  \\\n",
       "0            J  Accessibility guidelines place restrictions on...   \n",
       "1            J  Horizontal federated learning (HFL) enables di...   \n",
       "2            J  We present Rigel, an interactive system for ra...   \n",
       "3            J  We developed and validated a rating scale to a...   \n",
       "4            J  The success of DL can be attributed to hours o...   \n",
       "...        ...                                                ...   \n",
       "3615         C  The author applied image processing and volume...   \n",
       "3616         C  The problem of presenting and gaining deeper u...   \n",
       "3617         C  A hierarchical triangulation built from a digi...   \n",
       "3618         C  A methodology for guiding the choice of visual...   \n",
       "3619         C  The author describes a visualization model for...   \n",
       "\n",
       "                                    AuthorNames-Deduped  \\\n",
       "0                           Laura South;Michelle Borkin   \n",
       "1     Xumeng Wang;Wei Chen 0001;Jiazhi Xia;Zhen Wen;...   \n",
       "2     Ran Chen;Di Weng;Yanwei Huang;Xinhuan Shu;Jiay...   \n",
       "3     Tingying He;Petra Isenberg;Raimund Dachselt;To...   \n",
       "4               Anjul Tyagi;Cong Xie;Klaus Mueller 0001   \n",
       "...                                                 ...   \n",
       "3615                                   Nahum D. Gershon   \n",
       "3616                 Wayne E. Fordyce;Jeffrey Ventrella   \n",
       "3617              Lori L. Scarlatos;Theodosios Pavlidis   \n",
       "3618                                Philip K. Robertson   \n",
       "3619                                    Wolfgang Kr√ºger   \n",
       "\n",
       "                                            AuthorNames  \\\n",
       "0                        Laura South;Michelle A. Borkin   \n",
       "1     Xumeng Wang;Wei Chen;Jiazhi Xia;Zhen Wen;Rongc...   \n",
       "2     Ran Chen;Di Weng;Yanwei Huang;Xinhuan Shu;Jiay...   \n",
       "3     Tingying He;Petra Isenberg;Raimund Dachselt;To...   \n",
       "4                    Anjul Tyagi;Cong Xie;Klaus Mueller   \n",
       "...                                                 ...   \n",
       "3615                                       N.D. Gershon   \n",
       "3616                        W.E. Fordyce;J.J. Ventrella   \n",
       "3617                           L. Scarlatos;T. Pavlidis   \n",
       "3618                                     P.K. Robertson   \n",
       "3619                                         W. Krueger   \n",
       "\n",
       "                                      AuthorAffiliation  \\\n",
       "0     Northeastern University, USA;Northeastern Univ...   \n",
       "1     TMCC, CS, Nankai University, China;State Key L...   \n",
       "2     State Key Lab of CAD&CG, Zhejiang University, ...   \n",
       "3     Universit√© Paris-Saclay, CNRS, Inria, LISN, Fr...   \n",
       "4     Computer Science Department, Visual Analytics ...   \n",
       "...                                                 ...   \n",
       "3615                 MITRE Corporation, Mclean, VA, USA   \n",
       "3616  Research Computing Services, Syracuse Universi...   \n",
       "3617  Grumman Data Systems, Woodbury, NY, USA;Depart...   \n",
       "3618  Centre for Spatial Information Systems, Divisi...   \n",
       "3619                      ART COM e.V., Berlin, Germany   \n",
       "\n",
       "                                     InternalReferences  \\\n",
       "0     10.1109/TVCG.2011.185;10.1109/TVCG.2021.311482...   \n",
       "1     10.1109/TVCG.2015.2467618;10.1109/TVCG.2019.29...   \n",
       "2     10.1109/TVCG.2021.3114830;10.1109/VAST47406.20...   \n",
       "3     10.1109/INFVIS.2005.1532128;10.1109/TVCG.2006....   \n",
       "4     10.1109/VAST.2012.6400490;10.1109/TVCG.2019.29...   \n",
       "...                                                 ...   \n",
       "3615                                                NaN   \n",
       "3616                                                NaN   \n",
       "3617                                                NaN   \n",
       "3618                                                NaN   \n",
       "3619                                                NaN   \n",
       "\n",
       "                                         AuthorKeywords  AminerCitationCount  \\\n",
       "0     accessibility,photosensitive epilepsy,photosen...                  NaN   \n",
       "1     Federated learning,data heterogeneity,cluster ...                  NaN   \n",
       "2     Data transformation,self-service data transfor...                  NaN   \n",
       "3     Aesthetics,aesthetic pleasure,validated scale,...                  NaN   \n",
       "4     Deep Learning,Neural Network Architecture Sear...                  NaN   \n",
       "...                                                 ...                  ...   \n",
       "3615                                                NaN                 10.0   \n",
       "3616                                                NaN                  1.0   \n",
       "3617                                                NaN                 43.0   \n",
       "3618                                                NaN                  4.0   \n",
       "3619                                                NaN                  NaN   \n",
       "\n",
       "      CitationCount_CrossRef  PubsCited_CrossRef Award  \n",
       "0                        1.0                63.0   NaN  \n",
       "1                        3.0                43.0   NaN  \n",
       "2                        3.0                68.0   NaN  \n",
       "3                        1.0                79.0   NaN  \n",
       "4                        0.0                63.0   NaN  \n",
       "...                      ...                 ...   ...  \n",
       "3615                     5.0                 5.0   NaN  \n",
       "3616                     1.0                10.0   NaN  \n",
       "3617                     7.0                20.0   NaN  \n",
       "3618                    13.0                21.0   NaN  \n",
       "3619                    10.0                24.0   NaN  \n",
       "\n",
       "[3620 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = df[\"Abstract\"]\n",
    "abstracts_non_null = abstracts.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wepperso/miniconda3/envs/textprofiler/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from textprofilerbackend.transform import get_word_tokens_batch, get_byte_encoding_batch\n",
    "from textprofilerbackend.textclean import get_textcol_metadata_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"all-mpnet-base-v2\",  # best performing on leaderboard\n",
    "    # \"all-MiniLM-L6-v2\",  # smaller and faster\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embedding of shape torch.Size([3549, 768]) with all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "meta_data_dict = get_textcol_metadata_embeddings(abstracts_non_null, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract_text_length</th>\n",
       "      <th>Abstract_num_words</th>\n",
       "      <th>Abstract_max_word_length</th>\n",
       "      <th>Abstract_avg_word_length</th>\n",
       "      <th>Abstract_perc_special_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2109</td>\n",
       "      <td>286</td>\n",
       "      <td>22</td>\n",
       "      <td>6.377622</td>\n",
       "      <td>0.016121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1153</td>\n",
       "      <td>167</td>\n",
       "      <td>14</td>\n",
       "      <td>5.910180</td>\n",
       "      <td>0.019948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1543</td>\n",
       "      <td>220</td>\n",
       "      <td>16</td>\n",
       "      <td>6.018182</td>\n",
       "      <td>0.017498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1472</td>\n",
       "      <td>223</td>\n",
       "      <td>15</td>\n",
       "      <td>5.605381</td>\n",
       "      <td>0.025136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1879</td>\n",
       "      <td>272</td>\n",
       "      <td>17</td>\n",
       "      <td>5.911765</td>\n",
       "      <td>0.027674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>758</td>\n",
       "      <td>108</td>\n",
       "      <td>28</td>\n",
       "      <td>6.027778</td>\n",
       "      <td>0.026385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>786</td>\n",
       "      <td>111</td>\n",
       "      <td>29</td>\n",
       "      <td>6.090090</td>\n",
       "      <td>0.036896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>898</td>\n",
       "      <td>138</td>\n",
       "      <td>25</td>\n",
       "      <td>5.514493</td>\n",
       "      <td>0.026726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>879</td>\n",
       "      <td>116</td>\n",
       "      <td>26</td>\n",
       "      <td>6.586207</td>\n",
       "      <td>0.018203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>949</td>\n",
       "      <td>140</td>\n",
       "      <td>30</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>0.024236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3549 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Abstract_text_length  Abstract_num_words  Abstract_max_word_length  \\\n",
       "0                     2109                 286                        22   \n",
       "1                     1153                 167                        14   \n",
       "2                     1543                 220                        16   \n",
       "3                     1472                 223                        15   \n",
       "4                     1879                 272                        17   \n",
       "...                    ...                 ...                       ...   \n",
       "3544                   758                 108                        28   \n",
       "3545                   786                 111                        29   \n",
       "3546                   898                 138                        25   \n",
       "3547                   879                 116                        26   \n",
       "3548                   949                 140                        30   \n",
       "\n",
       "      Abstract_avg_word_length  Abstract_perc_special_chars  \n",
       "0                     6.377622                     0.016121  \n",
       "1                     5.910180                     0.019948  \n",
       "2                     6.018182                     0.017498  \n",
       "3                     5.605381                     0.025136  \n",
       "4                     5.911765                     0.027674  \n",
       "...                        ...                          ...  \n",
       "3544                  6.027778                     0.026385  \n",
       "3545                  6.090090                     0.036896  \n",
       "3546                  5.514493                     0.026726  \n",
       "3547                  6.586207                     0.018203  \n",
       "3548                  5.785714                     0.024236  \n",
       "\n",
       "[3549 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data_dict[\"heuristic_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0186,  0.0270, -0.0430,  ...,  0.0387, -0.0176, -0.0138],\n",
       "        [-0.0256,  0.0685, -0.0391,  ..., -0.0113, -0.0013,  0.0081],\n",
       "        [-0.0303, -0.0032, -0.0174,  ...,  0.0170, -0.0464, -0.0170],\n",
       "        ...,\n",
       "        [-0.0179, -0.0226, -0.0176,  ..., -0.0003,  0.0411,  0.0018],\n",
       "        [-0.0503,  0.0167, -0.0140,  ...,  0.0455, -0.0256, -0.0077],\n",
       "        [-0.0025,  0.0178, -0.0276,  ...,  0.0423, -0.0274,  0.0337]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data_dict[\"model_embeddings\"][\"all-mpnet-base-v2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = get_word_tokens_batch(abstracts_non_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = get_byte_encoding_batch(abstracts_non_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_null = df[df.Abstract.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_null = df_non_null.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_metadat = df_non_null.join(meta_data_dict[\"heuristic_metadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_metadat = df_with_metadat.reset_index().rename(columns={\"index\": \"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_metadat.to_parquet(\"../datasets/local/vis_papers/processed/vis_papers.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_long_format = pd.DataFrame(\n",
    "    [(word, i) for i, doc in enumerate(words) for word in doc], columns=[\"word\", \"id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_long_format = pd.DataFrame(\n",
    "    [(token, i) for i, doc in enumerate(tokens) for token in doc],\n",
    "    columns=[\"token\", \"id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_long_format.to_parquet(\n",
    "    \"../datasets/local/vis_papers/processed/vis_papers_tokens.parquet\"\n",
    ")\n",
    "word_long_format.to_parquet(\n",
    "    \"../datasets/local/vis_papers/processed/vis_papers_words.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3549, 768])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data_dict[\"model_embeddings\"][\"all-mpnet-base-v2\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    meta_data_dict[\"model_embeddings\"][\"all-mpnet-base-v2\"],\n",
    "    \"../datasets/local/vis_papers/processed/vis_papers_embeddings.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Accessibility'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b' guidelines'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b' place'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b' restrictions'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b' on'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689996</th>\n",
       "      <td>b'X'</td>\n",
       "      <td>3548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689997</th>\n",
       "      <td>b'&amp;gt'</td>\n",
       "      <td>3548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689998</th>\n",
       "      <td>b';&amp;'</td>\n",
       "      <td>3548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689999</th>\n",
       "      <td>b'gt'</td>\n",
       "      <td>3548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690000</th>\n",
       "      <td>b';'</td>\n",
       "      <td>3548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690001 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   token    id\n",
       "0       b'Accessibility'     0\n",
       "1         b' guidelines'     0\n",
       "2              b' place'     0\n",
       "3       b' restrictions'     0\n",
       "4                 b' on'     0\n",
       "...                  ...   ...\n",
       "689996              b'X'  3548\n",
       "689997            b'&gt'  3548\n",
       "689998             b';&'  3548\n",
       "689999             b'gt'  3548\n",
       "690000              b';'  3548\n",
       "\n",
       "[690001 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_parquet(\"../datasets/local/vis_papers/processed/vis_papers_tokens.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textprofiler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
